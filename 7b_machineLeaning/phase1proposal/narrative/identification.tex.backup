\section{Identification and Significance of the Problem or Opportunity, and Technical Approach}
%% {\em Define the specific technical problem or opportunity addressed by
%%  your application.  Provide enough background information so that the
%%  importance of the problem/opportunity is clear.  Indicate the overall
%%  technical approach to the problem/opportunity and the part that the
%%  proposed research plays in providing needed results.}

RNET Technologies Inc. (RNET) in Dayton, OH and Professor Boyana Norris from the University of Oregon (UO) are responding to the 2019 DOE 
SBIR/STTR (Release 1) Topic 7b: Technologies for Extreme Scale Computing (Software). RNET and UO are proposing are proposing the development of SASI (Smart Algorithm Selection through Inference); a machine learning based toolkit for the run-time optimization of generic numerical algorithms in terms of performance metrics such as CPU-time, memory consumption, energy usage, and resilience. SASI will be a generalization and extension of the project teams ongoing SBIR Phase II SolverSelector project (DOE TODO), developing performance based solver selection algorithms for linear solver packages such as PETSc. In addition to this ongoing work, RNET has extensive experience in various aspects of High Performance Computing such as performance 
optimization of numerical softwares and libraries, development of fine-grained power monitoring tools 
for HPC infrastructure, and large scale data analysis tools. Recent work in this area includes the 
development of high performance computing optimizations for the CFD solver, CSD solver, and fluid
structure interaction of the Air Force's Kestrel simulation tool. During the project, these optimizations
were shared with the Kestrel team and integrated into Kestrel. Dr. Boyana Norris has extensive experience 
in enabling technologies for high-performance simulations in computational science and engineering. 
Specifically, her research on performance analysis of scientific codes span a spectrum of topics, 
including static analysis, runtime performance monitoring, performance database management, postmortem 
performance analysis, and source transformation tools for performance tuning. Therefore, 
this team is well positioned to develop and commercialize the proposed performance tuning package for 
large scale numerical simulation with applications of exascale computing resources. 


\subsection{Identification and Significance}
\label{sec:introduction}

The modern-day numerical simulation tool-chain consists of an interconnected set of advanced 
numerical packages and toolkits designed to solve a complex but specific set of numerical subproblems. By allowing developers to focus on their specific area of expertise, the compartmentalization of the numerical simulation pipeline has lead to the rapid development of numerous simulation toolkits with unprecedented predictive capabilities, fidelity and accuracy. In an effort to further improve the nations numerical simulation capabilities, the DOE, academia and other government agencies have invested heavily in the development of efficient algorithms and implementations for solving the broad spectrum of subproblems that arise in numerical simulation.  The result of this investment is a robust collection of software packages designed to solve generic and specific numerical subproblems across a wide range of applications and on a broad spectrum of compute architectures. One only needs to look at the expansive collection of linear solvers and preconditioners available in PETSc to see the shear number of different implementations and algorithms that have been developed to solve just one, albeit important, class of numerical subproblem.  

The paradox of such rapid development is that it has quickly become impossible to fully understand the intricacies and details of the numerous subproblem solvers, let alone the mysterious sets of input parameters and configuration options that often accompany advanced numerical tools. While much work has taken place in optimizing the algorithms and implementations for specific problems and architectures, there is no simple governing theory for choosing between the numerous algorithms and configurations. Rather, the optimal method is, in practice, determined by experimentation and numerical folklore~\cite{EijkFuen2010:multistage}. While the experience and expertise provided by the domain scientists in tuning the algorithms cannot be underestimated, it is desirable to have toolkit-enabled functionality that automatically chooses the algorithm that is both appropriate for the computational problem at hand \emph{and} the computer architecture that will be used. Automatic selection of an appropriate algorithm and configuration can lead to benefits such as reduced memory requirement, lower execution time, fewer synchronization points in a parallel computation and so forth. 

As an example, consider the large sparse linear systems that arise when solving a transient nonlinear partial differential equation. In many cases, the linear solver used to solve these systems is the key computational kernel of the entire simulation, taking place multiple times per nonlinear solve. While one could take a guess as to the best linear solver based on coarse grained problem characteristics and experience, it is all but impossible to robustly determine the best solver in all cases. In fact, it has been shown that there is no uniformly optimal linear solver for general matrix-vector systems \cite{TODO}. Moreover, Eller \cite{Eller2012} showed that as the simulation progresses and the linear systems produced by the simulation changes, the best preconditioned iterative solver to solve each linear system can also change. Similarly, in applications with dynamic mesh adaptation, runtime changes in the structure of the mesh ( both physical and geometrical ) have also been shown to lead to changes in the linear system and hence, the optimal linear solver. The memory constraints of the solver can also change according to the code implementation or architecture of the machine, highlighting the fact that the compute architecture also plays a huge role in the performance of different algorithms. In other words, for optimal performance, the choice of linear solver should not be a static, a-priori design parameter, but rather, a dynamic, architecture dependent decision made based on the properties of the problem and the performance goals of the user. A similar argument holds for almost all numerical subproblems solvers, including eigensolvers, nonlinear solvers, graph algorithms and nonlinear optimization routines.      

To address this need, RNET and the University of Oregon are proposing the Smart Algorithm selection through Inference (SASI) framework. SASI will use machine learning to inform smart runtime algorithm selection and optimization in existing numerical simulations and libraries. The SASI framework will be a generalization of the ideas, lessons and workflows developed during the project teams previous work on automatic solver selection for linear solvers, eigen-solvers and graph algorithms. In that work, it was shown that SASI style performance models were capable of repeatedly predicting, with an extremely high accuracy (i.e., 98\%+), the performance of numerical algorithms and solver configurations across a wide range of applications and domains.

While SASI will be portable to any compute architecture (GPU, Cloud FPGA, etc.), the framework developed in this project will target the automatic optimization of numerical algorithms designed for execution on multi-node distributed memory systems ranging on user owned clusters up to leadership class exa-scale machines. The large costs associated with exa-scale computing will make SASI based performance optimizations particularly important on exascale machines. In addition to the aforementioned performance optimization routines, SASI models will give developers an avenue for predicting the performance of numerical algorithms on exa-scale resources. In that case, developers will be able to access the merits of integrating a new solver algorithm or library with little to no overhead. Moreover, SASI will allow developers to optimize simulations based on any measurable metric. The billion way concurrency that will be available on exa-scale is expected to amplify issues related to concurrency, power consumption, resiliency and latency; hence, being able to optimize simulations based on these metrics will be essential if users are to fully test the limits of this new and exciting technology. Ultimately, SASI will allow developers to ship tools that run optimally on any architecture, speeding up development across the entire design pipeline; from early stage testing on single desktops through to final exascale production runs.


\subsubsection{The SASI Framework}

SASI will guide the user through the process training, building an using machine learning models targeted at algorithm optimization, automating the process  where ever possible. As shown in Figure~\ref{fig:workflow}, the process of building a SASI model can be split into four distinct components; feature determination, data collection, model building and efficient software integration, each of which is rife with intricate details and nuances that must be addressed to ensure optimal performance in the final simulation:

\begin{itemize}
 \item {\bf Feature Determination:} Perhaps the most difficult component of building a SASI model is that of feature determination and evaluation. In machine learning terminology, a feature is any obtainable metric, measurement or observation that can be made about the target phenomenon. Determination of an informative, discriminating and independent set of features is a crucial step in the creation of unbiased and useful classification and regression based machine learning algorithms such as those used in SASI. With regards to SASI, a feature must represent a computable metric of the computational model (i.e, the linear system in a linear solver or the graph in graph solvers), that can be used to indicate or predict the performance of an algorithm when applied to a specific problem and on a specific architecture. 
 
 Because feature extraction is required during data collection \emph{and} at runtime, it is extremely important that it be as computationally efficient as possible; overly expensive feature calculations can quickly eat up the run-time savings associated with picking the optimal solver if one is not very careful.  For linear solvers, metrics such as the number of nonzeros and the absolute trace of the matrix where found to be both cheap and informative, whereas metrics such as the two norm or the spectral radius where to expensive to be used in a real-world application (see Section~\ref{sec:linearsolvers}. 
 
 \item Data Collection: Also key for an accurate and informative machine learning model is a large and diverse set of training data. In the context of SASI, training data takes the form of a set of measurements obtained by applying the different algorithms and configurations to a diverse set of sample problems. For linear solvers, this means solving a large number of matrix-vector systems using a wide variety of linear solvers, preconditioners and input parameters. Likewise, for graph algorithms, the training data set consists of measurements and features obtained by solving a collection of graph problems using a range of graph algorithms. Data collection is the most expensive step in SASI workflow; however, once an initial dataset has been built, it can be reused and extended continuously, quickly making up for the initial cost. 
 
 It is the accuracy, volume and variability of the training data that ultimately determines the accuracy of the machine learning model. As such, it is essential that the training data collected be analyzed to ensure it is acceptable for use in a machine learning model; it is all to easy to create a large, but narrow set of training data capable of informing a machine learning model with high levels of accuracy in cross validation tests, but with little to no predictive capabilities in real world situations. As such, SASI will also include a set of database analysis tools designed to access the variability and appropriateness of the training data (see section~\ref{TODO}). 
 
 \item Model building and Optimization. The third component of the SASI workflow involves choosing a machine learning algorithm, building the model, and testing the result. Previous results have shown that simple machine learning algorithms such a a single descision tree or a Random forest can be used to create cheap, serializable and highly accurate machine learning models for SASI based problems. For instance, the decision tree based J48 algorithm was the most accurate algorithm for the matrix-free based linear solver based SASI models outlined in Section~\ref{TODO}. 
 
 Rather than recreating the wheel, SASI will build the machine learing models by interfacing to one (or more) of numerous machine learning frameworks (the python based sci-kit, Facebook's Torch, Google's TensorFlow, the university of Waikato's WEKA, etc) already in existence. In doing so, SASI will provide users with access to a wide range of fully tested and verified machine learning tools. To aid in algorithm selection, SASI will be equipt with tools for automatically building and testing models using standard machine learing based verification methods such as k-fold cross validation and the 66-33\% split testing methods. Feature set reduction tools will also be included. These tools will automatically determine the most efficient feature set for which the model still produces a pre-set level of accuracy. Feature set reduction is important as it reduces the computational burden associated with using SASI models, thereby increasing the performance increases that can be obtained. 
 
 \item Model Integration. The final component of the SASI workflow is software integration. Integrating SASI into existing simulations is somewhat software dependent. For that reason, SASI will implement the software indirections and interfaces required for loading the pre-built model at run-time, and for obtaining a algorithm prediction, but will leave it up to the user to integrate the required software calls into existing software. At runtime, the user will be required to implement three software calls; (1) extract the required features from the computational model and (2) set the algorithm based on the result returned from the the machine learning model. Users will be free to pick and choose when the machine learning model is used to optimize the algorithm ( i.e, optimization of a linear solver routine could occur once per Newton iteration, once per time step, or even once per simulation).  This more general approach to integration will allow SASI to be integrated into a wide range of software applications, without enforcing restrictions on the formating and style of the intended simulation code. 
\end{itemize}

\subsubsection{SolverSelector: Automatic Solver Selection for Linear Solvers} 

The SASI workflow will be built upon the experience, lessons and work flows developed by the project team as part its ongoing DOE Phase II SBIR project developing automated solver selection algorithms and software for the linear solvers in nuclear engineering applications (RNET and UO, DOE \#TODO), as well as for additional models for eigensolvers and for graph algorithms (UO). In what follows, we provide a brief overview of the SASI models developed for linear solvers, and present results highlighting the accuracy at which SASI based models can predict solver performance when built correctly. 

For linear solvers, the computational model is a matrix vector system, $A\mathbf{x} = \mathbf{b}$. As such, the features are metrics based primarily on the matrix. Table~\ref{TODO} shows two feature sets that were found to lead to an accurate machine learning model. 

\begin{table*}[h]
\centering
\caption{Matrix-free: Reduced Feature Sets}
\label{reduced_sets}
\resizebox{\linewidth}{!}{%
\begin{tabular}{|c|c|c|}    \hline  

Features                   & Reduced Set 1  & Reduced Set 2 \\ \hline\hline
Min. Non zeros/row         & X              & X             \\ \hline
Lower Bandwidth            & X              & X             \\ \hline
Non Zero Pattern Symmetry   & X              &               \\ \hline
Infinity Norm              & X              &               \\ \hline
Column Variance            & X              & X             \\ \hline
Diagonal Non Zeros         & X              & X             \\ \hline
Diagonal Average           & X              & X             \\ \hline

\end{tabular}}
\end{table*}

In both cases, the feature sets were designed such that they maximized the accuracy per computational cost of the feature extraction and solver prediction process. In SolverSelector, feature set reduction was completed manually by applying multiple attribute evaluators with different search methods to select the features that are significant and contribute the most towards the classification process. The SASI framework will automate this process by running each feature set through a rigorous set of attribute evaluators and search methods to produce a set capable of producing a machine learning model with a high level of accuracy per computational cost. (See Section~\ref{workplan-feature-set}

To test and build the linear solver based models we used data collected from two sources; the SuiteSparse matrix collection (formally the Florida Sparse matrix collection) and a set of matrices extracted from the MOOSE testing suite by scaling the appropriate input parameters. MOOSE is a multiphysics finite element code built on top of libMesh that provides a number of finite element examples across a broad range of application areas \cite{TODO-MOOSE}. 

Training data was obtained by solving the system $A\mathbf{x} = \mathbf{b}$ for each of the matrices in the data set using a range of linear solver configurations available in PETSc. In each case, $\mathbf{b}$ was a vector of ones and a random initial guess was used.  As an example, the MOOSE dataset contains approximately 50000 independent data points made up of TODO solver configurations applied to TODO different matrices. The size and breadth of these datasets is continuously increasing, with new data points being added on a regular basis. 

A binary classification was used to differentiate between a good and a bad linear solver configuration for each matrix in the dataset. A solver was classified as ``good'' for a given matrix if the measured value (i.e., CPU time) for that solver is within $p \in (0,1)\%$ of the best solver for the given matrix. In that way, we obtain a list of solvers that are considered to have acceptable performance for a given set of feature values. Choosing $p$ is an important and difficult process that depends heavily on the training set. As $p$ approaches $1$, the number of acceptable solvers decreases, increasing the chance that no good solvers are found for a given matrix. Likewise, choosing $p$ to small leads to a large number of acceptable solvers, potentially reducing the performance gains that can be achieved. We have found that setting $p\approx 80\%$ leads to a good balance for linear solvers, whereby a small number of solvers are classified as good. SASI will provide a more robust mechanism for determining the optimal value of $p$ using a mixture of steepest decent optimization methods and 10-fold cross validation tests. 

The downside of a classification based machine learning models is that they do not rank the solvers in order of effectiveness. Rather, the model can only be used to predict the performance of a single solver. This means that for any given feature set, there may be multiple solvers classified as ``good''. Moreover, the only way to find the list of ``good'' solvers is to loop through and test every solver configuration available in the database. For linear solvers. we simply returns the first ``good'' solver as the optimal solver, a decision that balances the risk of not getting the very best solver against the costs of testing every solver in the database. The project team has developed a ranking based machine learning algorithm for graph problems; however, the results of those tests are yet to be verified. Those ranking based machine learning models will be integrated into the SASI framework in Phase II. 

Table~\ref{TODO} shows 10-fold cross validation and 66-33\% split validation tests for the machine learning models built using the data sets. Table~\ref{TODO:A} shows the accuracy. In this case, we show the accuracy obtained from various machine learning algorithms, built using Weka~\cite{Weka}, based on optimizing for CPU Time using the MOOSE and PETSc based training data. Overall, the models obtained for linear solvers where capable of classified ``good'' solvers as ``good'' with an accuracy of up to $TODO\%$ in both the 10-fold cross validation and 33-66\% split validation tests. 

Expanding on this, Table~\ref{TODO} shows the performance gains obtained using the model for run-time algorithm selection inside some of the tests in the MOOSE test suite when compared to the default linear solvers specified by the developers of those tests. It is important to note that these tests are, in most cases, not indicative of a real world application and are likely not highly optimized; however, these results do highlight the fact that the integration of SASI based models is an effective mechanism for the optimization of linear solvers.

The goal of the SolverSelector project was to create a plugin like infrastructure for the automatic detection and selection of the optimal linear solver configuration inside nuclear physics simulations. The realization of that infrastructure is the SolverSelector API. The SolverSelector API, written utilizing C++11 templates, is designed to mimic a standard linear solver routine. The SolverSelector API has been successfully injected PETSc as an additional Krylov subspace solver (KSP). In this way, users can build, validate and use SASI based machine learning models inside PETSc through a single command line parameter and a simple input file. Internally, the SolverSelector API extracts the features, predicts the optimal solver, sets up an internal KSP solver, and solves the system. This is done in a completely non-intrusive way requiring no modification of the PETSc source code. Currently PETSc versions 3.4 and 3.7 are supported with patches for additional versions available on request. The interface is designed for use with both standard matrix based and matrix-free based iterative and direct solvers, and has been successfully used inside PETSc based simulation software such as MOOSE, LibMesh and PROTEUS. 

\subsubsection{SASI} 

In summary, SASI will facilitate the development of numerical software that automatically adapts to the problem being solved and to the compute environment being used, irrespective of the size (laptop, petascale, exascale, cloud) and type (CPU, GPU, FPGA, etc) of the available resources, with applications across all areas of numerical simulation. Overall, the models built using this approach will ensure the efficient usage of large-scale resources (both in terms of time and energy). The predictive capabilities of the model will also reduce the computational burden associated with the development of new algorithms by providing developers with a fast, low cost method for predicting the performance of the algorithm configuration on large-scale machines. 

Whereas the SolverSelector API is specifically designed for linear solvers; SASI will be designed as a generic toolkit for the development of smart algorithm detection models. In many ways, the specific interfaces of the SolverSelector API, i.e., the PETSc interface described above, will represent an example of SASI model and interface that can be built using the SASI framework. The SolverSelector project and API is scheduled for completion in July 2019 with the commercialization plan being to sell service contracts for the integration of SolverSelector into existing simulation toolkits, as well as the API itself. Because SolverSelector is specifically designed for linear solvers, SolverSelector will continue to be the tool of choice for that domain. 

RNET and UO have been working on SolverSelector for three years, highlighting the difficult nature of building a SASI model from scratch. SASI was born out of the desire to extend the work completed on linear solvers to a more generic audience and to drive the uptake, notoriety and usability of machine learning models for performance tuning in advanced numerical simulation. To that end, our hope is that SASI will address the needs of a large customer base while also increasing sales of the SolverSelector API. For that reason,As such, we believe SASI is best released as Open Source software, with the commercialization plan being to offer support, training, extension and/or integration contracts to government agencies and private companies looking for automated optimization of existing simulation toolkits.  Open source, contract based commercialization is quickly becoming the norm in the numerical simulation community, primarily because it appeals to a user-base that almost exclusively deals in free open source software. In return, the results, papers and simulation toolkits released utilizing SASI models act as free, no-cost marketing for SASI, further driving uptake of SASI while also increasing the likelihood of obtaining new service contracts. 

